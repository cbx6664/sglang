{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25610d23",
   "metadata": {},
   "source": [
    "## Common Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c03d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import statistics\n",
    "from typing import Callable, Tuple, List, Optional\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from use_eplb import load_csv_to_tensor\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "\n",
    "def calculate_gpu_loads(original_weights: torch.Tensor, num_gpus: int):\n",
    "    num_layers, num_experts = original_weights.shape\n",
    "    experts_per_gpu = num_experts // num_gpus\n",
    "\n",
    "    assert num_experts % num_gpus == 0, \"Experts cannot be evenly divided among GPUs.\"\n",
    "\n",
    "    gpu_loads = torch.zeros((num_layers, num_gpus), dtype=original_weights.dtype)\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        for gpu_idx in range(num_gpus):\n",
    "            start_idx = gpu_idx * experts_per_gpu\n",
    "            end_idx = (gpu_idx + 1) * experts_per_gpu\n",
    "            gpu_loads[layer_idx, gpu_idx] = original_weights[\n",
    "                layer_idx, start_idx:end_idx\n",
    "            ].sum()\n",
    "\n",
    "    return gpu_loads\n",
    "\n",
    "\n",
    "def save_gpu_loads_to_csv(\n",
    "    gpu_loads: torch.Tensor, output_folder: str, file_name: str, num_gpus: int\n",
    "):\n",
    "    gpu_loads_df = pd.DataFrame(\n",
    "        gpu_loads.numpy(),\n",
    "        columns=[f\"GPU{i}\" for i in range(num_gpus)],\n",
    "        index=list(range(gpu_loads.shape[0])),\n",
    "    )\n",
    "    csv_save_path = os.path.join(output_folder, file_name)\n",
    "    gpu_loads_df.to_csv(csv_save_path)\n",
    "\n",
    "\n",
    "def plot_gpu_loads_analysis(\n",
    "    gpu_loads: torch.Tensor, heatmap_save_path: str, boxplot_save_path: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot normalized heatmap and boxplot of GPU loads.\n",
    "\n",
    "    Args:\n",
    "        gpu_loads (torch.Tensor): Tensor of shape [58, 8] (layers x GPUs).\n",
    "        heatmap_save_path (str): File path to save heatmap.\n",
    "        boxplot_save_path (str): File path to save boxplot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    # Normalize the gpu loads per layer\n",
    "    layer_sums = gpu_loads.sum(dim=1, keepdim=True)  # Sum across GPUs for each layer\n",
    "    normalized_gpu_loads = gpu_loads / layer_sums  # Each row sums to 1\n",
    "\n",
    "    # 1. Heatmap: Normalized Load per layer per GPU\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        normalized_gpu_loads.numpy(),\n",
    "        cmap=\"Reds\",\n",
    "        annot=True,\n",
    "        fmt=\".2f\",  # Show 2 decimal places for better precision\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"label\": \"Normalized Load\"},\n",
    "        yticklabels=list(range(gpu_loads.shape[0])),  # Layer IDs\n",
    "        annot_kws={\"size\": 6},\n",
    "    )\n",
    "    plt.xlabel(\"GPU Index\")\n",
    "    plt.ylabel(\"Layer ID\")\n",
    "    plt.title(\"Normalized GPU Loads per Layer\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heatmap_save_path)\n",
    "    print(f\"Normalized heatmap saved to: {heatmap_save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Boxplot: Distribution of normalized GPU loads across layers\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=normalized_gpu_loads.numpy())\n",
    "    plt.axhline(\n",
    "        y=1.0 / normalized_gpu_loads.shape[1], color=\"blue\", linestyle=\"-\"\n",
    "    )  # Ideal line\n",
    "    overall_std = normalized_gpu_loads.numpy().flatten().std()\n",
    "    plt.annotate(\n",
    "        xy=(0.98, 0.98),\n",
    "        xycoords=\"axes fraction\",\n",
    "        text=f\"Overall Std Dev: σ = {overall_std:.4f}\",\n",
    "        ha=\"right\",\n",
    "        va=\"top\",\n",
    "        fontsize=10,\n",
    "        color=\"blue\",\n",
    "        bbox=dict(\n",
    "            boxstyle=\"round,pad=0.3\", edgecolor=\"gray\", facecolor=\"white\", alpha=0.7\n",
    "        ),\n",
    "    )\n",
    "    plt.xlabel(\"GPU Index\")\n",
    "    plt.ylabel(\"Normalized Load\")\n",
    "    plt.title(\"GPU Load Distribution Across Layers (Normalized Boxplot)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(boxplot_save_path)\n",
    "    print(f\"Normalized boxplot saved to: {boxplot_save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def remap_weights(\n",
    "    phy2log: torch.Tensor, original_weights: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Remap the original logical expert weights according to the phy2log mapping.\n",
    "\n",
    "    Args:\n",
    "        phy2log (torch.Tensor): A tensor of shape [58, 256], where each value is a logical_expert_id.\n",
    "        original_weights (torch.Tensor): A tensor of shape [58, 256], where the index is the logical_expert_id and the value is the corresponding weight.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A new tensor of shape [58, 256], where each physical expert has its remapped weight.\n",
    "    \"\"\"\n",
    "    num_layers, num_physical_experts = phy2log.shape\n",
    "    new_weights = torch.zeros_like(phy2log, dtype=original_weights.dtype)\n",
    "\n",
    "    for layer_idx in range(num_layers):\n",
    "        # Get the mapping from physical experts to logical experts for this layer\n",
    "        logical_ids = phy2log[layer_idx]  # Shape: [256]\n",
    "        # Fetch the corresponding weights from original_weights using the logical expert IDs\n",
    "        new_weights[layer_idx] = original_weights[layer_idx][logical_ids]\n",
    "\n",
    "    return new_weights\n",
    "\n",
    "\n",
    "def normalize_gpu_loads(gpu_loads: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Normalize GPU loads layer-wise so that each row sums to 1.\n",
    "    \"\"\"\n",
    "    layer_sums = gpu_loads.sum(dim=1, keepdim=True)  # Sum across GPUs for each layer\n",
    "    normalized_gpu_loads = gpu_loads / layer_sums\n",
    "    return normalized_gpu_loads\n",
    "\n",
    "\n",
    "def natural_sort_key(s: str) -> List:\n",
    "    \"\"\"Generate a natural sort key for strings.\n",
    "\n",
    "    Args:\n",
    "        s: Input string to be sorted\n",
    "\n",
    "    Returns:\n",
    "        A list that can be used for natural sorting\n",
    "    \"\"\"\n",
    "    return [\n",
    "        int(text) if text.isdigit() else text.lower() for text in re.split(r\"(\\d+)\", s)\n",
    "    ]\n",
    "\n",
    "\n",
    "def load_csv_to_tensor(input_folder: str) -> Optional[torch.Tensor]:\n",
    "    \"\"\"Load CSV files from a folder and convert them to a tensor.\n",
    "\n",
    "    Each CSV file represents one layer, and is converted to one row in the output tensor.\n",
    "\n",
    "    Args:\n",
    "        input_folder: Path to folder containing CSV files\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor of shape [num_layers, num_experts] or None if an error occurs\n",
    "    \"\"\"\n",
    "    # Get all csv files and sort them naturally\n",
    "    csv_files = sorted(\n",
    "        [\n",
    "            os.path.join(input_folder, f)\n",
    "            for f in os.listdir(input_folder)\n",
    "            if f.endswith(\".csv\")\n",
    "        ],\n",
    "        key=natural_sort_key,\n",
    "    )\n",
    "    num_layers = len(csv_files)\n",
    "\n",
    "    if num_layers == 0:\n",
    "        print(f\"No CSV files found in {input_folder}\")\n",
    "        return None\n",
    "\n",
    "    # Initialize a list to store rows\n",
    "    rows = []\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(csv_file, header=None)\n",
    "            # Sum up all rows in the CSV file\n",
    "            row_sums = df.sum(axis=0).values\n",
    "            # Append to the list as a row\n",
    "            rows.append(row_sums)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {csv_file}: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Stack all rows into a single tensor of shape [num_layers, num_experts]\n",
    "    return torch.tensor(rows, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def count_expert_moves(assignment: torch.Tensor) -> int:\n",
    "    \"\"\"input one-hot assignment\"\"\"\n",
    "    nb_experts_per_gpu = assignment.shape[1] // assignment.shape[0]\n",
    "    return sum(\n",
    "        [\n",
    "            sum(\n",
    "                [\n",
    "                    int(assignment[gpu][expert].item())\n",
    "                    for expert in range(assignment.shape[1])\n",
    "                    if (expert // nb_experts_per_gpu) != gpu\n",
    "                ]\n",
    "            )\n",
    "            for gpu in range(assignment.shape[0])\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_naive_assignment(nb_gpus: int, nb_experts: int) -> torch.Tensor:\n",
    "    \"\"\"return vanilla one-hot assignment of experts to GPUs\"\"\"\n",
    "    nb_experts_per_gpu = nb_experts // nb_gpus\n",
    "    return torch.Tensor(\n",
    "        [\n",
    "            [\n",
    "                (\n",
    "                    1\n",
    "                    if i < (j + 1) * nb_experts_per_gpu and i >= j * nb_experts_per_gpu\n",
    "                    else 0\n",
    "                )\n",
    "                for i in range(nb_experts)\n",
    "            ]\n",
    "            for j in range(nb_gpus)\n",
    "        ]\n",
    "    ).long()\n",
    "\n",
    "\n",
    "def get_readable_assignment(assignment: torch.Tensor) -> str:\n",
    "    \"\"\"return a readable string of the one-hot assignment\"\"\"\n",
    "    assignment_str = \"\"\n",
    "    for gpu in range(assignment.shape[0]):\n",
    "        assignment_str += f\"GPU {gpu}:\"\n",
    "        for expert, value in enumerate(assignment[gpu]):\n",
    "            if value:\n",
    "                assignment_str += f\" {expert}\"\n",
    "        assignment_str += \"\\n\"\n",
    "    return assignment_str\n",
    "\n",
    "\n",
    "def phy_to_assignment(\n",
    "    phy2log: torch.Tensor, nb_gpus: int, nb_experts: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    convert phy2log to one-hot assignment, if assignment[0][32] = 1, then in this layer, logical_expert 32 is located on gpu0.\n",
    "    \"\"\"\n",
    "    assert nb_experts % nb_gpus == 0, \"Experts cannot be evenly divided among GPUs.\"\n",
    "    return torch.sum(\n",
    "        torch.nn.functional.one_hot(phy2log).view(nb_gpus, nb_experts // nb_gpus, -1),\n",
    "        dim=1,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_gpu_load(\n",
    "    assignment: torch.Tensor,\n",
    "    hotness: torch.Tensor,\n",
    "):\n",
    "    return torch.matmul(assignment.float(), hotness.float())\n",
    "\n",
    "\n",
    "def adjust_hotness(hotness: torch.Tensor, assignment: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - hotness: [E], total logical hotness\n",
    "        - assignment: [G, E], 1 if logical expert is on GPU\n",
    "\n",
    "    Returns:\n",
    "        - adjusted_hotness: [E], hotness per replica (logical expert / replica count)\n",
    "    \"\"\"\n",
    "    assignment = assignment.float()\n",
    "    replica_count = assignment.sum(dim=0)  # [E]\n",
    "    adjusted_hotness = hotness.float() / replica_count.clamp(min=1)\n",
    "    return adjusted_hotness\n",
    "\n",
    "\n",
    "def measure_execution_time(func: Callable[[], dict], warmup: int, repeat: int):\n",
    "    for _ in range(warmup):\n",
    "        func()\n",
    "\n",
    "    times = []\n",
    "    final_result = None\n",
    "    for _ in range(repeat):\n",
    "        start = time.perf_counter()\n",
    "        final_result = func()\n",
    "        end = time.perf_counter()\n",
    "        times.append((end - start) * 1000)  # ms\n",
    "\n",
    "    return {\n",
    "        \"result\": final_result,\n",
    "        \"avg\": statistics.mean(times),\n",
    "        \"std\": statistics.stdev(times) if repeat > 1 else 0,\n",
    "        \"min\": min(times),\n",
    "        \"max\": max(times),\n",
    "        \"all_times\": times,\n",
    "    }\n",
    "\n",
    "\n",
    "def minimize_moves(self, hotness: torch.Tensor, assignments: torch.Tensor) -> torch.Tensor:\n",
    "    bins = torch.arange(\n",
    "        0,\n",
    "        int(torch.max(hotness).item() + 11),\n",
    "        # int(0.5 * self.nb_experts),\n",
    "        10,\n",
    "    )\n",
    "    digitized = torch.bucketize(hotness, bins, right=True)\n",
    "    # Try sort approach rather than bin approach\n",
    "\n",
    "    binned = [\n",
    "        torch.arange(self.nb_experts)[digitized == i].tolist()\n",
    "        for i in range(1, len(bins))\n",
    "    ]\n",
    "    assignment_indices = torch.arange(self.nb_experts)[torch.argsort(assignments)]\n",
    "    for i, expert in enumerate(assignments):\n",
    "        gpu = i // self.nb_experts_per_gpu\n",
    "        # Nothing to change. The expert is on the original GPU\n",
    "        if (\n",
    "            gpu * self.nb_experts_per_gpu <= expert\n",
    "            and expert < (gpu + 1) * self.nb_experts_per_gpu\n",
    "        ):\n",
    "            continue\n",
    "        current_expert_bin = digitized[expert]\n",
    "        experts_in_same_bin = binned[current_expert_bin - 1]\n",
    "        for i, same_bin_expert in enumerate(experts_in_same_bin):\n",
    "            # We found an expert with the same kind of hotness that belongs to the current GPU\n",
    "            if (\n",
    "                same_bin_expert != expert\n",
    "                and gpu * self.nb_experts_per_gpu <= same_bin_expert\n",
    "                and same_bin_expert < (gpu + 1) * self.nb_experts_per_gpu\n",
    "            ):\n",
    "                # We get the index of the original gpu\n",
    "                # gpu_ind = np.where(assignments[:, same_bin_expert] == 1)[0]\n",
    "                # assert len(gpu_ind) == 1\n",
    "                # gpu_ind = gpu_ind[0]\n",
    "                # if gpu_ind == gpu:\n",
    "                # continue\n",
    "                (\n",
    "                    assignments[assignment_indices[expert]],\n",
    "                    assignments[assignment_indices[same_bin_expert]],\n",
    "                ) = (\n",
    "                    assignments[assignment_indices[same_bin_expert]],\n",
    "                    assignments[assignment_indices[expert]],\n",
    "                )\n",
    "\n",
    "                # We don't want this expert to be swapped again\n",
    "                del experts_in_same_bin[i]\n",
    "\n",
    "                break\n",
    "\n",
    "    return assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6acc2",
   "metadata": {},
   "source": [
    "## vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b8d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bingxche\\AppData\\Local\\Temp\\ipykernel_40152\\2794219900.py:202: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  return torch.tensor(rows, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized heatmap saved to: C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\\vanilla\\vanilla_gpu_loads_heatmap.png\n",
      "Normalized boxplot saved to: C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\\vanilla\\vanilla_gpu_loads_boxplot.png\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "input_folder = r\"C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\"\n",
    "output_folder = os.path.join(input_folder, \"vanilla\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "original_weights = load_csv_to_tensor(input_folder)\n",
    "num_gpus = 8\n",
    "vanilla_gpu_loads = calculate_gpu_loads(original_weights, num_gpus)\n",
    "csv_save_path = os.path.join(output_folder, \"vanilla_gpu_loads.csv\")\n",
    "save_gpu_loads_to_csv(vanilla_gpu_loads, output_folder, csv_save_path, num_gpus)\n",
    "\n",
    "heatmap_save_path = os.path.join(output_folder, \"vanilla_gpu_loads_heatmap.png\")\n",
    "boxplot_save_path = os.path.join(output_folder, \"vanilla_gpu_loads_boxplot.png\")\n",
    "plot_gpu_loads_analysis(\n",
    "    gpu_loads=vanilla_gpu_loads,\n",
    "    heatmap_save_path=heatmap_save_path,\n",
    "    boxplot_save_path=boxplot_save_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0b0b69",
   "metadata": {},
   "source": [
    "## EPLB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f73a1e",
   "metadata": {},
   "source": [
    "### EPLB ALgorithm Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c38f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def balanced_packing(\n",
    "    weight: torch.Tensor, num_packs: int\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Pack n weighted objects to m packs, such that each bin contains exactly n/m objects and the weights of all packs\n",
    "    are as balanced as possible.\n",
    "\n",
    "    Parameters:\n",
    "        weight: [X, n], the weight of each item\n",
    "        num_packs: number of packs\n",
    "\n",
    "    Returns:\n",
    "        pack_index: [X, n], the pack index of each item\n",
    "        rank_in_pack: [X, n], the rank of the item in the pack\n",
    "    \"\"\"\n",
    "    num_layers, num_groups = weight.shape\n",
    "    assert num_groups % num_packs == 0\n",
    "    groups_per_pack = num_groups // num_packs\n",
    "\n",
    "    if groups_per_pack == 1:\n",
    "        pack_index = torch.arange(\n",
    "            weight.size(-1), dtype=torch.int64, device=weight.device\n",
    "        ).expand(weight.shape)\n",
    "        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n",
    "        return pack_index, rank_in_pack\n",
    "\n",
    "    indices = weight.float().sort(-1, descending=True).indices.cpu()  # O(n log n)\n",
    "    pack_index = torch.full_like(weight, fill_value=-1, dtype=torch.int64, device=\"cpu\")\n",
    "    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n",
    "    for i in range(num_layers):\n",
    "        pack_weights = [0] * num_packs\n",
    "        pack_items = [0] * num_packs\n",
    "        for group in indices[i]:\n",
    "            pack = min(\n",
    "                (i for i in range(num_packs) if pack_items[i] < groups_per_pack),\n",
    "                key=pack_weights.__getitem__,\n",
    "            )\n",
    "            assert pack_items[pack] < groups_per_pack\n",
    "            pack_index[i, group] = pack\n",
    "            rank_in_pack[i, group] = pack_items[pack]\n",
    "            pack_weights[pack] += weight[i, group]\n",
    "            pack_items[pack] += 1\n",
    "    return pack_index, rank_in_pack\n",
    "\n",
    "\n",
    "def replicate_experts(\n",
    "    weight: torch.Tensor, num_phy: int\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Replicate `num_log` experts to `num_phy` replicas, such that the maximum load of all replicas is minimized.\n",
    "\n",
    "    Parameters:\n",
    "        weight: [X, num_log]\n",
    "        num_phy: total number of experts after replication\n",
    "\n",
    "    Returns:\n",
    "        phy2log: [X, num_phy], logical expert id of each physical expert\n",
    "        rank: [X, num_phy], the replica rank\n",
    "        logcnt: [X, num_log], number of replicas for each logical expert\n",
    "    \"\"\"\n",
    "    n, num_log = weight.shape\n",
    "    num_redundant = num_phy - num_log\n",
    "    assert num_redundant >= 0\n",
    "    device = weight.device\n",
    "    phy2log = torch.arange(num_phy, dtype=torch.int64, device=device).repeat(n, 1)\n",
    "    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n",
    "    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n",
    "    arangen = torch.arange(n, dtype=torch.int64, device=device)\n",
    "    for i in range(num_log, num_phy):\n",
    "        redundant_indices = (weight / logcnt).max(dim=-1).indices\n",
    "        phy2log[:, i] = redundant_indices\n",
    "        rank[:, i] = logcnt[arangen, redundant_indices]\n",
    "        logcnt[arangen, redundant_indices] += 1\n",
    "    return phy2log, rank, logcnt\n",
    "\n",
    "\n",
    "def rebalance_experts_hierarchical(\n",
    "    weight: torch.Tensor,\n",
    "    num_physical_experts: int,\n",
    "    num_groups: int,\n",
    "    num_nodes: int,\n",
    "    num_gpus: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        weight: [num_moe_layers, num_logical_experts]\n",
    "        num_physical_experts: number of physical experts after replication\n",
    "        num_groups: number of expert groups\n",
    "        num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster\n",
    "        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n",
    "\n",
    "    Returns:\n",
    "        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n",
    "        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n",
    "        logical_count: [num_moe_layers, num_logical_experts]\n",
    "    \"\"\"\n",
    "    num_layers, num_logical_experts = weight.shape\n",
    "    assert num_logical_experts % num_groups == 0\n",
    "    group_size = num_logical_experts // num_groups\n",
    "    assert num_groups % num_nodes == 0\n",
    "    groups_per_node = num_groups // num_nodes\n",
    "    assert num_gpus % num_nodes == 0\n",
    "    assert num_physical_experts % num_gpus == 0\n",
    "    phy_experts_per_gpu = num_physical_experts // num_gpus\n",
    "\n",
    "    def inverse(perm: torch.Tensor) -> torch.Tensor:\n",
    "        inv = torch.empty_like(perm)\n",
    "        inv.scatter_(\n",
    "            1,\n",
    "            perm,\n",
    "            torch.arange(perm.size(1), dtype=torch.int64, device=perm.device).expand(\n",
    "                perm.shape\n",
    "            ),\n",
    "        )\n",
    "        return inv\n",
    "\n",
    "    # Step 1: pack groups to nodes\n",
    "    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n",
    "    group_pack_index, group_rank_in_pack = balanced_packing(tokens_per_group, num_nodes)\n",
    "    log2mlog = (\n",
    "        (\n",
    "            (group_pack_index * groups_per_node + group_rank_in_pack) * group_size\n",
    "        ).unsqueeze(-1)\n",
    "        + torch.arange(group_size, dtype=torch.int64, device=group_pack_index.device)\n",
    "    ).flatten(-2)\n",
    "    mlog2log = inverse(log2mlog)\n",
    "\n",
    "    # Step 2: construct redundant experts within nodes\n",
    "    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n",
    "    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n",
    "        -1, num_logical_experts // num_nodes\n",
    "    )\n",
    "    phy2mlog, phyrank, mlogcnt = replicate_experts(\n",
    "        tokens_per_mlog, num_physical_experts // num_nodes\n",
    "    )\n",
    "\n",
    "    # Step 3: pack physical_experts to GPUs\n",
    "    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n",
    "    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n",
    "    pack_index, rank_in_pack = balanced_packing(tokens_per_phy, num_gpus // num_nodes)\n",
    "    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n",
    "    pphy2phy = inverse(phy2pphy)\n",
    "\n",
    "    pphy2mlog = phy2mlog.gather(\n",
    "        -1, pphy2phy\n",
    "    )  # [num_layers * num_nodes, num_log_per_nodes]\n",
    "    pphy2mlog = (\n",
    "        pphy2mlog.view(num_layers, num_nodes, -1)\n",
    "        + torch.arange(\n",
    "            0,\n",
    "            num_logical_experts,\n",
    "            num_logical_experts // num_nodes,\n",
    "            device=group_pack_index.device,\n",
    "        ).view(1, -1, 1)\n",
    "    ).flatten(-2)\n",
    "    pphy2log = mlog2log.gather(-1, pphy2mlog)\n",
    "    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n",
    "    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n",
    "    return pphy2log, pphyrank, logcnt\n",
    "\n",
    "\n",
    "def rebalance_experts(\n",
    "    weight: torch.Tensor,\n",
    "    num_replicas: int,\n",
    "    num_groups: int,\n",
    "    num_nodes: int,\n",
    "    num_gpus: int,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Entry point for expert-parallelism load balancer.\n",
    "\n",
    "    Parameters:\n",
    "        weight: [layers, num_logical_experts], the load statistics for all logical experts\n",
    "        num_replicas: number of physical experts, must be a multiple of `num_gpus`\n",
    "        num_groups: number of expert groups\n",
    "        num_nodes: number of server nodes, where the intra-node network (e.g, NVLink) is faster\n",
    "        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n",
    "\n",
    "    Returns:\n",
    "        physical_to_logical_map: [layers, num_replicas], the expert index of each replica\n",
    "        logical_to_physical_map: [layers, num_logical_experts, X], the replica indices for each expert\n",
    "        expert_count: [layers, num_logical_experts], number of physical replicas for each logical expert\n",
    "    \"\"\"\n",
    "    num_layers, num_logical_experts = weight.shape\n",
    "    weight = weight.float().cpu()\n",
    "    if num_groups % num_nodes == 0:\n",
    "        # use hierarchical load-balance policy\n",
    "        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n",
    "            weight, num_replicas, num_groups, num_nodes, num_gpus\n",
    "        )\n",
    "    else:\n",
    "        # use global load-balance policy\n",
    "        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n",
    "            weight, num_replicas, 1, 1, num_gpus\n",
    "        )\n",
    "    maxlogcnt = logcnt.max().item()\n",
    "    log2phy: torch.Tensor = torch.full(\n",
    "        (num_layers, num_logical_experts, maxlogcnt),\n",
    "        -1,\n",
    "        dtype=torch.int64,\n",
    "        device=logcnt.device,\n",
    "    )\n",
    "    log2phy.view(num_layers, -1).scatter_(\n",
    "        -1,\n",
    "        phy2log * maxlogcnt + phyrank,\n",
    "        torch.arange(num_replicas, dtype=torch.int64, device=log2phy.device).expand(\n",
    "            num_layers, -1\n",
    "        ),\n",
    "    )\n",
    "    return phy2log, log2phy, logcnt\n",
    "\n",
    "\n",
    "__all__ = [\"rebalance_experts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a724b",
   "metadata": {},
   "source": [
    "### DeepSeek-v3 EPLB 256 replicas new token dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e2dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measuring total EPLB execution time across all layers...\n",
      "\n",
      "EPLB Execution Time Stats (over 5 runs):\n",
      "  • Average: 600.54 ms\n",
      "  • Std Dev: 32.18 ms\n",
      "  • Min:     567.04 ms\n",
      "  • Max:     652.90 ms\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'original_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 71\u001b[0m\n\u001b[0;32m     67\u001b[0m logcnt \u001b[38;5;241m=\u001b[39m eplb_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogcnt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 原始 expert load 重映射\u001b[39;00m\n\u001b[0;32m     70\u001b[0m bldm_256_replicas_new_weights \u001b[38;5;241m=\u001b[39m remap_weights(\n\u001b[1;32m---> 71\u001b[0m     phy2log\u001b[38;5;241m=\u001b[39mphy2log, original_weights\u001b[38;5;241m=\u001b[39m\u001b[43moriginal_weights\u001b[49m\n\u001b[0;32m     72\u001b[0m )\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# 计算负载\u001b[39;00m\n\u001b[0;32m     75\u001b[0m bldm_256_replicas_gpu_loads \u001b[38;5;241m=\u001b[39m calculate_gpu_loads(\n\u001b[0;32m     76\u001b[0m     bldm_256_replicas_new_weights, num_gpus\n\u001b[0;32m     77\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'original_weights' is not defined"
     ]
    }
   ],
   "source": [
    "input_folder = r\"C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\"\n",
    "output_folder = os.path.join(input_folder, \"eplb\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "weights = load_csv_to_tensor(input_folder)\n",
    "if weights is None:\n",
    "    raise ValueError(f\"Failed to load weights from {input_folder}\")\n",
    "\n",
    "# ========== EPLB 测试配置 ==========\n",
    "eplb_config = {\n",
    "    \"num_replicas\": 256,  # Number of physical experts\n",
    "    \"num_groups\": 1,\n",
    "    \"num_nodes\": 1,\n",
    "    \"num_gpus\": 8,\n",
    "}\n",
    "\n",
    "\n",
    "def run_eplb_all_layers():\n",
    "    phy2log, log2phy, logcnt = rebalance_experts(\n",
    "        weight=weights,\n",
    "        num_replicas=eplb_config[\"num_replicas\"],\n",
    "        num_groups=eplb_config[\"num_groups\"],\n",
    "        num_nodes=eplb_config[\"num_nodes\"],\n",
    "        num_gpus=eplb_config[\"num_gpus\"],\n",
    "    )\n",
    "    return {\"phy2log\": phy2log, \"log2phy\": log2phy, \"logcnt\": logcnt}\n",
    "\n",
    "\n",
    "# ========== EPLB 执行时间测量 ==========\n",
    "print(\"\\nMeasuring total EPLB execution time across all layers...\")\n",
    "\n",
    "\n",
    "repeat_runs = 5\n",
    "warmup_runs = 2\n",
    "eplb_stats = measure_execution_time(\n",
    "    run_eplb_all_layers, warmup=warmup_runs, repeat=repeat_runs\n",
    ")\n",
    "\n",
    "# ========== 打印 EPLB 时间统计 ==========\n",
    "print(f\"\\nEPLB Execution Time Stats (over {repeat_runs} runs):\")\n",
    "print(f\"  • Average: {eplb_stats['avg']:.2f} ms\")\n",
    "print(f\"  • Std Dev: {eplb_stats['std']:.2f} ms\")\n",
    "print(f\"  • Min:     {eplb_stats['min']:.2f} ms\")\n",
    "print(f\"  • Max:     {eplb_stats['max']:.2f} ms\")\n",
    "\n",
    "# ========== 后续处理 ==========\n",
    "phy2log = eplb_stats[\"result\"][\"phy2log\"]\n",
    "log2phy = eplb_stats[\"result\"][\"log2phy\"]\n",
    "logcnt = eplb_stats[\"result\"][\"logcnt\"]\n",
    "\n",
    "# 原始 expert load 重映射\n",
    "bldm_256_replicas_new_weights = remap_weights(\n",
    "    phy2log=phy2log, original_weights=original_weights\n",
    ")\n",
    "\n",
    "# 计算负载\n",
    "bldm_256_replicas_gpu_loads = calculate_gpu_loads(\n",
    "    bldm_256_replicas_new_weights, num_gpus\n",
    ")\n",
    "csv_save_path = os.path.join(output_folder, \"eplb_256_replicas_gpu_loads.csv\")\n",
    "save_gpu_loads_to_csv(\n",
    "    bldm_256_replicas_gpu_loads, output_folder, csv_save_path, num_gpus\n",
    ")\n",
    "\n",
    "# 可视化\n",
    "heatmap_save_path = os.path.join(\n",
    "    output_folder, \"eplb_256_replicas_gpu_loads_heatmap.png\"\n",
    ")\n",
    "boxplot_save_path = os.path.join(\n",
    "    output_folder, \"eplb_256_replicas_gpu_loads_boxplot.png\"\n",
    ")\n",
    "plot_gpu_loads_analysis(\n",
    "    gpu_loads=bldm_256_replicas_gpu_loads,\n",
    "    heatmap_save_path=heatmap_save_path,\n",
    "    boxplot_save_path=boxplot_save_path,\n",
    ")\n",
    "\n",
    "# experts moves\n",
    "all_assignments = []\n",
    "all_expert_moves = 0\n",
    "print(f\"phy2log: {phy2log}\")\n",
    "for i in range(phy2log.shape[0]):\n",
    "    assignment = phy_to_assignment(\n",
    "        phy2log=phy2log[i],\n",
    "        nb_gpus=eplb_config[\"num_gpus\"],\n",
    "        nb_experts=eplb_config[\"num_replicas\"],\n",
    "    )\n",
    "\n",
    "    layerwise_num_expert_moves = count_expert_moves(assignment)\n",
    "    print(\n",
    "        f\"\\nLayer {i} expert moves:{layerwise_num_expert_moves} \\nassignment:\\n{get_readable_assignment(assignment)}\"\n",
    "    )\n",
    "    all_expert_moves += layerwise_num_expert_moves\n",
    "    all_assignments.append(assignment)\n",
    "\n",
    "\n",
    "print(f\"Number of expert moves: {all_expert_moves}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe3db0",
   "metadata": {},
   "source": [
    "### Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viztracer import VizTracer\n",
    "\n",
    "with VizTracer(output_file=\"eplb_profile.json\") as tracer:\n",
    "    tracer.start()\n",
    "    results = run_eplb_all_layers()\n",
    "    tracer.stop()\n",
    "    tracer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c81f6",
   "metadata": {},
   "source": [
    "## BLDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef522d",
   "metadata": {},
   "source": [
    "### BLDM Tensor Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed6a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os\n",
    "import pandas as pd\n",
    "from balancing.balancers.load_balancer import LoadBalancer\n",
    "\n",
    "\n",
    "class BLDMBalancer(LoadBalancer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        number_of_gpus: int,\n",
    "        number_of_experts: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(number_of_gpus, number_of_experts, **kwargs)\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "    # Section 2: https://link.springer.com/chapter/10.1007/3-540-36494-3_51\n",
    "    @staticmethod\n",
    "    def argsort(seq):\n",
    "        # http://stackoverflow.com/questions/3071415/efficient-method-to-calculate-the-rank-vector-of-a-list-in-python\n",
    "        return sorted(range(len(seq)), key=seq.__getitem__)\n",
    "\n",
    "    def get_graph_name(self) -> str:\n",
    "        return \"BLDM\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __algo(buckets: List[List[List[Tuple[int, int]]]]):\n",
    "        d_diff = []\n",
    "        sums = []\n",
    "\n",
    "        for partition in buckets:\n",
    "            local_sums = torch.tensor(\n",
    "                [sum(elem[0] for elem in subset) for subset in partition],\n",
    "                dtype=torch.float32,\n",
    "            )\n",
    "            sorted_sums = torch.argsort(local_sums)\n",
    "            sums.append(sorted_sums)\n",
    "            d_diff.append(local_sums[sorted_sums[-1]] - local_sums[sorted_sums[0]])\n",
    "        sorted_d_diff = torch.argsort(torch.stack(d_diff))\n",
    "        p1_ind = sorted_d_diff[-1].item()\n",
    "        p2_ind = sorted_d_diff[-2].item()\n",
    "        p1 = buckets[p1_ind]\n",
    "        p2 = buckets[p2_ind]\n",
    "        new_partition = [\n",
    "            p1[sums[p1_ind][j].item()]\n",
    "            + p2[sums[p2_ind][len(sums[p2_ind]) - j - 1].item()]\n",
    "            for j in range(len(sums[p1_ind]))\n",
    "        ]\n",
    "\n",
    "        del buckets[p1_ind]\n",
    "        if p1_ind < p2_ind:\n",
    "            p2_ind -= 1\n",
    "        del buckets[p2_ind]\n",
    "        buckets.append(new_partition)\n",
    "\n",
    "    def balance(self, hotness: Tensor) -> Union[Tensor, None]:\n",
    "        # From wikipedia description\n",
    "        buckets: List[List[List[Tuple[int, int]]]] = []\n",
    "        sorted_vals, sorted_idx = torch.sort(hotness)  # 已是升序\n",
    "        hotnesses = list(\n",
    "            zip(sorted_vals.tolist(), sorted_idx.tolist())  # 仅用于后面构造 buckets\n",
    "        )\n",
    "        assert len(hotnesses) % self.nb_gpus == 0\n",
    "\n",
    "        # Initialization phase\n",
    "        m = len(hotnesses) // self.nb_gpus\n",
    "        k = 0\n",
    "        for i in range(m):  # O(n)\n",
    "            local_bucket = []\n",
    "            for j in range(self.nb_gpus):\n",
    "                local_bucket.append([hotnesses[k]])\n",
    "                k = k + 1\n",
    "            buckets.append(local_bucket)\n",
    "\n",
    "        # Applying algo\n",
    "        while len(buckets) > 1:\n",
    "            BLDMBalancer.__algo(buckets)\n",
    "\n",
    "        # Retrieving solution\n",
    "        solution = buckets[0]\n",
    "        self.solution = solution\n",
    "        # if self.minimize_moves:\n",
    "        # return LoadBalancer.minimize_moves(hotness, np.array(assignment))\n",
    "        sequential_solution = []\n",
    "        for partition in self.solution:\n",
    "            for _, expert in partition:\n",
    "                sequential_solution.append(expert)\n",
    "\n",
    "        self.solution = torch.Tensor(sequential_solution)\n",
    "        return self.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222cad8",
   "metadata": {},
   "source": [
    "### BLDM Algorithm Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1711cc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import os\n",
    "import pandas as pd\n",
    "from balancing.balancers.load_balancer import LoadBalancer\n",
    "\n",
    "\n",
    "class BLDMBalancer(LoadBalancer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        number_of_gpus: int,\n",
    "        number_of_experts: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(number_of_gpus, number_of_experts, **kwargs)\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "    # Section 2: https://link.springer.com/chapter/10.1007/3-540-36494-3_51\n",
    "    @staticmethod\n",
    "    def argsort(seq):\n",
    "        # http://stackoverflow.com/questions/3071415/efficient-method-to-calculate-the-rank-vector-of-a-list-in-python\n",
    "        return sorted(range(len(seq)), key=seq.__getitem__)\n",
    "\n",
    "    def get_graph_name(self) -> str:\n",
    "        return \"BLDM\"\n",
    "\n",
    "    @staticmethod\n",
    "    def __algo(buckets: List[List[List[Tuple[int, int]]]]):\n",
    "        d_diff = []\n",
    "        sums = []\n",
    "\n",
    "        for partition in buckets:\n",
    "            local_sums = [sum(elem[0] for elem in subset) for subset in partition]\n",
    "            sorted_sums = BLDMBalancer.argsort(local_sums)\n",
    "            sums.append(sorted_sums)\n",
    "            d_diff.append(local_sums[sorted_sums[-1]] - local_sums[sorted_sums[0]])\n",
    "        sorted_d_diff = BLDMBalancer.argsort(d_diff)\n",
    "        p1_ind = sorted_d_diff[-1]\n",
    "        p2_ind = sorted_d_diff[-2]\n",
    "        p1 = buckets[p1_ind]\n",
    "        p2 = buckets[p2_ind]\n",
    "        new_partition = [\n",
    "            p1[sums[p1_ind][j]] + p2[sums[p2_ind][len(sums[p2_ind]) - j - 1]]\n",
    "            for j in range(len(sums[p1_ind]))\n",
    "        ]\n",
    "\n",
    "        del buckets[p1_ind]\n",
    "        if p1_ind < p2_ind:\n",
    "            p2_ind = p2_ind - 1\n",
    "        del buckets[p2_ind]\n",
    "        buckets.append(new_partition)\n",
    "\n",
    "    def balance(self, hotness: Tensor) -> Union[Tensor, None]:\n",
    "        # From wikipedia description\n",
    "        buckets: List[List[List[Tuple[int, int]]]] = []\n",
    "        hotnesses = hotness.tolist()\n",
    "        hotnesses = [(hotness, expert) for expert, hotness in enumerate(hotnesses)]\n",
    "        hotnesses.sort(key=lambda x: x[0])  # O(n log n)\n",
    "        assert len(hotnesses) % self.nb_gpus == 0\n",
    "\n",
    "        # Initialization phase\n",
    "        m = len(hotnesses) // self.nb_gpus\n",
    "        k = 0\n",
    "        for i in range(m):  # O(n)\n",
    "            local_bucket = []\n",
    "            for j in range(self.nb_gpus):\n",
    "                local_bucket.append([hotnesses[k]])\n",
    "                k = k + 1\n",
    "            buckets.append(local_bucket)\n",
    "\n",
    "        # Applying algo\n",
    "        while len(buckets) > 1:\n",
    "            BLDMBalancer.__algo(buckets)\n",
    "\n",
    "        # Retrieving solution\n",
    "        solution = buckets[0]\n",
    "        self.solution = solution\n",
    "        # if self.minimize_moves:\n",
    "        # return LoadBalancer.minimize_moves(hotness, np.array(assignment))\n",
    "        sequential_solution = []\n",
    "        for partition in self.solution:\n",
    "            for _, expert in partition:\n",
    "                sequential_solution.append(expert)\n",
    "\n",
    "        self.solution = torch.Tensor(sequential_solution)\n",
    "        return self.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba928cd5",
   "metadata": {},
   "source": [
    "### Run BLDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221b9c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measuring total BLDM execution time across all layers...\n",
      "Saved balanced phy2log mapping to C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\\bldm\\bldm_phy2log.csv\n",
      "\n",
      "BLDM Execution Time Stats (over 5 runs):\n",
      "  • Average: 150.75 ms\n",
      "  • Std Dev: 8.15 ms\n",
      "  • Min:     141.73 ms\n",
      "  • Max:     163.94 ms\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from typing import Callable\n",
    "\n",
    "\n",
    "# config\n",
    "input_folder = r\"C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\"\n",
    "output_folder = os.path.join(input_folder, \"bldm\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "num_gpus = 8\n",
    "num_experts = 256\n",
    "warmup_runs = 2\n",
    "repeat_runs = 5\n",
    "\n",
    "# load hotness data\n",
    "all_hotness = load_csv_to_tensor(input_folder)  # [num_layers, 256]\n",
    "num_layers = all_hotness.shape[0]\n",
    "balancer = BLDMBalancer(\n",
    "    number_of_gpus=num_gpus, number_of_experts=num_experts, minimize_moves=False\n",
    ")\n",
    "\n",
    "\n",
    "# wrap the function to run all layers\n",
    "def run_all_layers_bldm() -> list:\n",
    "    all_seq = []\n",
    "    for layer_idx in range(num_layers):\n",
    "        hotness = all_hotness[layer_idx]\n",
    "        sequential = balancer.balance(hotness).to(torch.int64)\n",
    "        all_seq.append(sequential.cpu().numpy())\n",
    "    return all_seq\n",
    "\n",
    "\n",
    "# execute the function and measure time\n",
    "print(\"Measuring total BLDM execution time across all layers...\")\n",
    "stats = measure_execution_time(\n",
    "    run_all_layers_bldm, warmup=warmup_runs, repeat=repeat_runs\n",
    ")\n",
    "\n",
    "# save phy2log mapping\n",
    "all_phy2log = torch.tensor(stats[\"results\"], dtype=torch.int64)\n",
    "all_assignments = [\n",
    "    phy_to_assignment(all_phy2log[i], num_gpus, num_experts)\n",
    "    for i in range(all_phy2log.shape[0])\n",
    "]\n",
    "all_assignments_tensor = torch.stack(all_assignments, dim=0)\n",
    "\n",
    "all_gpu_loads = []\n",
    "for i in range(all_assignments_tensor.shape[0]):\n",
    "    layerwise_gpu_loads = get_gpu_load(all_assignments_tensor[i], all_hotness[i])\n",
    "    all_gpu_loads.append(layerwise_gpu_loads)\n",
    "all_gpu_loads_tensor = torch.stack(all_gpu_loads, dim=0)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(all_phy2log.numpy())\n",
    "csv_path = os.path.join(output_folder, \"bldm_phy2log.csv\")\n",
    "df.to_csv(csv_path, index=False, header=False)\n",
    "print(f\"Saved balanced phy2log mapping to {csv_path}\")\n",
    "\n",
    "# print results\n",
    "print(f\"\\nBLDM Execution Time Stats (over {repeat_runs} runs):\")\n",
    "print(f\"  • Average: {stats['avg']:.2f} ms\")\n",
    "print(f\"  • Std Dev: {stats['std']:.2f} ms\")\n",
    "print(f\"  • Min:     {stats['min']:.2f} ms\")\n",
    "print(f\"  • Max:     {stats['max']:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a943ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized heatmap saved to: C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\\bldm\\bldm_256_replicas_gpu_loads_heatmap.png\n",
      "Normalized boxplot saved to: C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\\bldm\\bldm_256_replicas_gpu_loads_boxplot.png\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\"\n",
    "output_folder = os.path.join(input_folder, \"bldm\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "heatmap_save_path = os.path.join(output_folder, \"bldm_256_replicas_gpu_loads_heatmap.png\")\n",
    "boxplot_save_path = os.path.join(output_folder, \"bldm_256_replicas_gpu_loads_boxplot.png\")\n",
    "plot_gpu_loads_analysis(gpu_loads=all_gpu_loads_tensor, heatmap_save_path=heatmap_save_path, boxplot_save_path=boxplot_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789247f5",
   "metadata": {},
   "source": [
    "### Profile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2380268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from viztracer import VizTracer\n",
    "\n",
    "with VizTracer(output_file=\"bldm_profile.json\") as tracer:\n",
    "    tracer.start()\n",
    "    results = run_all_layers_bldm()\n",
    "    tracer.stop()\n",
    "    tracer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df97054",
   "metadata": {},
   "source": [
    "## Simple Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb59d34f",
   "metadata": {},
   "source": [
    "### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220747da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class ReplicationBalancer(LoadBalancer):\n",
    "    additional_experts_per_gpu: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        number_of_gpus: int,\n",
    "        number_of_experts: int,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(number_of_gpus, number_of_experts, **kwargs)\n",
    "        self.additional_experts_per_gpu = kwargs[\"additional_experts_per_gpu\"]\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"\"\"{super().__str__()}\n",
    "                Max experts on one GPU: {self.additional_experts_per_gpu}\n",
    "                \"\"\"\n",
    "\n",
    "    def get_graph_name(self) -> str:\n",
    "        return f\"Replication_Max_{self.additional_experts_per_gpu}\"\n",
    "\n",
    "    def balance(self, hotness: Tensor) -> Union[Tensor, None]:\n",
    "        hottest_experts = torch.argsort(hotness).flip(dims=[0])[\n",
    "            : self.additional_experts_per_gpu\n",
    "        ]\n",
    "        ones = torch.ones(self.nb_experts_per_gpu)\n",
    "        assignment = torch.zeros(\n",
    "            size=(self.nb_gpus, self.nb_experts), dtype=torch.int64\n",
    "        )\n",
    "        for gpu in range(self.nb_gpus):\n",
    "            assignment[gpu][\n",
    "                gpu * self.nb_experts_per_gpu : (gpu + 1) * self.nb_experts_per_gpu\n",
    "            ] = ones\n",
    "        for hottest_expert in hottest_experts:\n",
    "            for gpu in range(self.nb_gpus):\n",
    "                # We are not on the original GPU the expert has been assigned to\n",
    "                if gpu != hottest_expert // self.nb_experts_per_gpu:\n",
    "                    assignment[gpu][hottest_expert] = 1\n",
    "        return assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d290ea",
   "metadata": {},
   "source": [
    "### max 8 extra experts per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b9d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_replication():\n",
    "    all_assignments = []\n",
    "    all_gpu_loads = []\n",
    "\n",
    "    for layer_idx in range(vanilla_hotness.shape[0]):\n",
    "        hotness = vanilla_hotness[layer_idx]\n",
    "        assignment = balancer.balance(hotness)\n",
    "        assert assignment is not None\n",
    "        adjusted_hot = adjust_hotness(hotness, assignment)\n",
    "        all_assignments.append(assignment)\n",
    "        layerwise_gpu_load = get_gpu_load(assignment, adjusted_hot)\n",
    "        all_gpu_loads.append(layerwise_gpu_load)\n",
    "\n",
    "    return {\n",
    "        \"assignments\": all_assignments,\n",
    "        \"gpu_loads\": all_gpu_loads,\n",
    "    }\n",
    "    \n",
    "\n",
    "input_folder = r\"C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\"\n",
    "output_folder = os.path.join(input_folder, f\"8_simple_replication\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "balancer = ReplicationBalancer(\n",
    "    number_of_gpus=8,\n",
    "    number_of_experts=256,\n",
    "    additional_experts_per_gpu=8,\n",
    "    minimize_moves=False,\n",
    ")\n",
    "vanilla_hotness = load_csv_to_tensor(input_folder)\n",
    "\n",
    "print(\"Measuring total ReplicationBalancer execution time across all layers...\")\n",
    "replication_stats = measure_execution_time(run_simple_replication, warmup=warmup_runs, repeat=repeat_runs)\n",
    "\n",
    "\n",
    "print(f\"\\nReplicationBalancer Execution Time Stats (over {repeat_runs} runs):\")\n",
    "print(f\"  • Average: {replication_stats['avg']:.2f} ms\")\n",
    "print(f\"  • Std Dev: {replication_stats['std']:.2f} ms\")\n",
    "print(f\"  • Min:     {replication_stats['min']:.2f} ms\")\n",
    "print(f\"  • Max:     {replication_stats['max']:.2f} ms\")\n",
    "\n",
    "\n",
    "# to tensor [num_layers, nb_gpus, nb_experts]\n",
    "all_assignments_tensor = torch.stack(replication_stats['results']['assignments'], dim=0)\n",
    "all_gpu_loads_tensor = torch.stack(replication_stats['results']['gpu_loads'], dim=0)\n",
    "\n",
    "# print(f\"all gpu loads: {all_gpu_loads}\")\n",
    "all_gpu_loads_df = pd.DataFrame(all_gpu_loads_tensor.numpy())\n",
    "csv_path = os.path.join(output_folder, \"8_simple_replication_gpu_loads.csv\")\n",
    "all_gpu_loads_df.to_csv(csv_path, index=False, header=False)\n",
    "\n",
    "print(f\"all_assignments_tensor shape: {all_assignments_tensor.shape}\")\n",
    "print(f\"all_gpu_loads_tensor shape: {all_gpu_loads_tensor.shape}\")\n",
    "\n",
    "\n",
    "heatmap_save_path = os.path.join(output_folder, \"8_simple_replication_gpu_loads_heatmap.png\")\n",
    "boxplot_save_path = os.path.join(output_folder, \"8_simple_replication_gpu_loads_boxplot.png\")\n",
    "plot_gpu_loads_analysis(gpu_loads=all_gpu_loads_tensor, heatmap_save_path=heatmap_save_path, boxplot_save_path=boxplot_save_path)\n",
    "\n",
    "\n",
    "# experts moves\n",
    "all_assignments = []\n",
    "all_expert_moves = 0\n",
    "for i in range(phy2log.shape[0]):\n",
    "    assignment = all_assignments_tensor[i]\n",
    "    layerwise_num_expert_moves = count_expert_moves(assignment)\n",
    "    all_expert_moves += layerwise_num_expert_moves\n",
    "    all_assignments.append(assignment)\n",
    "    \n",
    "\n",
    "\n",
    "print(f\"Number of expert moves: {all_expert_moves}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f04e54",
   "metadata": {},
   "source": [
    "### max 16 extra experts per GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a708d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_replication():\n",
    "    all_assignments = []\n",
    "    all_gpu_loads = []\n",
    "\n",
    "    for layer_idx in range(vanilla_hotness.shape[0]):\n",
    "        hotness = vanilla_hotness[layer_idx]\n",
    "        assignment = balancer.balance(hotness)\n",
    "        assert assignment is not None\n",
    "        adjusted_hot = adjust_hotness(hotness, assignment)\n",
    "        all_assignments.append(assignment)\n",
    "        layerwise_gpu_load = get_gpu_load(assignment, adjusted_hot)\n",
    "        all_gpu_loads.append(layerwise_gpu_load)\n",
    "\n",
    "    return {\n",
    "        \"assignments\": all_assignments,\n",
    "        \"gpu_loads\": all_gpu_loads,\n",
    "    }\n",
    "    \n",
    "\n",
    "input_folder = r\"C:\\Users\\bingxche\\data\\log\\deepseek-v3_tp8_mixtral_dataset_5000_prompts_vanilla\\moe_token_dist\"\n",
    "output_folder = os.path.join(input_folder, f\"16_simple_replication\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "balancer = ReplicationBalancer(\n",
    "    number_of_gpus=8,\n",
    "    number_of_experts=256,\n",
    "    additional_experts_per_gpu=16,\n",
    "    minimize_moves=False,\n",
    ")\n",
    "vanilla_hotness = load_csv_to_tensor(input_folder)\n",
    "\n",
    "print(\"Measuring total ReplicationBalancer execution time across all layers...\")\n",
    "replication_stats = measure_execution_time(run_simple_replication, warmup=warmup_runs, repeat=repeat_runs)\n",
    "\n",
    "\n",
    "print(f\"\\nReplicationBalancer Execution Time Stats (over {repeat_runs} runs):\")\n",
    "print(f\"  • Average: {replication_stats['avg']:.2f} ms\")\n",
    "print(f\"  • Std Dev: {replication_stats['std']:.2f} ms\")\n",
    "print(f\"  • Min:     {replication_stats['min']:.2f} ms\")\n",
    "print(f\"  • Max:     {replication_stats['max']:.2f} ms\")\n",
    "\n",
    "\n",
    "# to tensor [num_layers, nb_gpus, nb_experts]\n",
    "all_assignments_tensor = torch.stack(replication_stats['results']['assignments'], dim=0)\n",
    "all_gpu_loads_tensor = torch.stack(replication_stats['results']['gpu_loads'], dim=0)\n",
    "\n",
    "# print(f\"all gpu loads: {all_gpu_loads}\")\n",
    "all_gpu_loads_df = pd.DataFrame(all_gpu_loads_tensor.numpy())\n",
    "csv_path = os.path.join(output_folder, \"8_simple_replication_gpu_loads.csv\")\n",
    "all_gpu_loads_df.to_csv(csv_path, index=False, header=False)\n",
    "\n",
    "print(f\"all_assignments_tensor shape: {all_assignments_tensor.shape}\")\n",
    "print(f\"all_gpu_loads_tensor shape: {all_gpu_loads_tensor.shape}\")\n",
    "\n",
    "\n",
    "heatmap_save_path = os.path.join(output_folder, \"8_simple_replication_gpu_loads_heatmap.png\")\n",
    "boxplot_save_path = os.path.join(output_folder, \"8_simple_replication_gpu_loads_boxplot.png\")\n",
    "plot_gpu_loads_analysis(gpu_loads=all_gpu_loads_tensor, heatmap_save_path=heatmap_save_path, boxplot_save_path=boxplot_save_path)\n",
    "\n",
    "\n",
    "# experts moves\n",
    "all_assignments = []\n",
    "all_expert_moves = 0\n",
    "for i in range(phy2log.shape[0]):\n",
    "    assignment = all_assignments_tensor[i]\n",
    "    layerwise_num_expert_moves = count_expert_moves(assignment)\n",
    "    all_expert_moves += layerwise_num_expert_moves\n",
    "    all_assignments.append(assignment)\n",
    "    \n",
    "\n",
    "\n",
    "print(f\"Number of expert moves: {all_expert_moves}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
